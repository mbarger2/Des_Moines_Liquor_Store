# Predicting Material Costs for Opening a Liquor Store in Des Moines Iowa
![image](https://user-images.githubusercontent.com/71361520/154779839-5d6c9c34-a99c-479f-8aee-3e12c1aed5b7.png)

## Context
The Iowa Department of Commerce logs every liquor sale sold by stores with class "E" liquor licenses (used for selling alcohol in bottled form for off-the-premises consumption), which is in turn published as open data by the State of Iowa. This data, which exceeds github's upload limit for file size, can be found at the following link: https://www.kaggle.com/residentmario/iowa-liquor-sales.  The data covers from the beginning of 2012 through October of 2017, with over 12 million sales of unique items made.  This means that every unique item sold is logged independently of any items it was sold with, along with many details including (but not limited to) the store number, item number, item quantity, item cost for the store to purchase, amount the item was sold for, and when it was sold. 

## Purpose
Using this information, I am researching how material costs trend year-to-year in the Des Moines city limits in order to inform prospective liquor store business owners of the material costs of liquor bottles to inform their business plan. Because the raw data is so extensive, Des Moines stores were chosen to use businesses that are all in a similar area with similar consumer patterns to help with model accuracy while still providing 100,000s of data points, as Des Moines is the most populated city in the state of Iowa.

## Contents
2 .ipynb files can be found in this repo, to show the cleaning and modeling approaches I took in handling the data to develop several models: Linear Regression, KNeighbor, Random Forest, and a simple mathematic model. The 1st part dives into the data, cleans over 190,000 Nan values (99.6% of all total Nans in the dataset), and  converts the columns to their respective appropriate datatypes. The 2nd part systemtically addresses which columns can be dropped and makes takes several different approaches to model the data using a few different combinations of variables. 

## Approach
While there are 26 columns in the raw data, about 6 were deemed important for my question about material cost trends: Item Number, Vendor Number, Store Number, Bottles Sold, Sold Bottle Cost, Volume Sold (L).   Ultimately, Bottle Volume (ml), Item Description, and Pack were used as the independent variables while State Bottle Cost was used  as the dependent, target variable. A logarithmic transformation was used on Volume Sold (L) and an aggregation of cost per sale was used on Item Number and Store Number to categorize how much each sale was for both variables.  The ranges of the scales were determined by trends seen in plots of the data: Item Number was categorized on a scale of 1-4 while Store Number had a scale of 1-5.

## Results
With the original file size of the entirety of the data at 3.47 gB, the raw data held nearly 12.6 million rows of data and over 192,000 nan values (1.53% of all data). Using over a dozen compiled dictionaries and additional functions, nan values were reduced to a total of 729, 0.0038% of the original nan values and 0.000059% of all data. However, despite multiple variations in each model, none of the Machine Learning models were accurate in predicting trends in how my chosen variables affected the cost of materials.  A simple line graph of average total cost per store each year was employed along with stats of the annual data (mean, median, quartiles, etc) to show a steady downward trend in liquor costs. Per an intercept-slope formula from a line of best fit, the costs are dropping annually and for the year of 2017, median costs are predicted to be $39,000 and $110,000 dollars for the 75th percentile. This appears somewhat low especially for the median cost due to slightly nonlinear tendencies from the data.

## Conclusion
The extremely poor results from the machine learning models indicate that the pricing of the liquor is not particularly defined by a particular pattern but rather is influenced by more human factors. The conclusion seems most likely since I committed to limiting my number of categories per object variables and applied an effective transformation to my numerical data. From experience, 5 or less categories per object variable helps model accuracy while any more tends to impede it. Ultimately I believe the data provided by the Department of Commerce is not sufficient to answer this particular question, though it is incredibly thorough and could be of great use in other business-related modeling.

## If There Was a Next Time
Given another go at this data, I would ask a different question since my first one did not yield effect results. Examples of useful questions include "How does local population affect sales" or "when are the slowest months for liquor sales in Iowa", as I believe the data could reveal information that would not be intuitive. In reflecting on how time could have been shortened in efficiently handling the data, the cleaning process could have been greatly shortened by cutting columns and unnecessary data for my specific goals earlier in the process. The use of dictionaries, functions, and maps were highly effective and would be immediately used again as well.



A presentation on this topic can be found at: https://slides.com/mbarger2/deck-3f99e9/edit
